REQUEST
Problem: This is a python actions.py file of Rasa chatbot import time
import requests
import re
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
from bs4 import BeautifulSoup

BASE_URL = 'https://www.kijiji.ca/'


start_page = 1

def get_original_url(address: str, sorting: str=None) -> str:
    if sorting:
        if 'low' in sorting or 'asc' in sorting:
            sorting = 'priceAsc'
        elif 'high' in sorting or 'desc' in sorting:
            sorting = 'priceDesc'
        room_and_rental_term_url = BASE_URL + f'b-for-rent/city-of-toronto/{address}/page-1/k0c30349001l1700273?sort={sorting}'
    else:
        room_and_rental_term_url = BASE_URL + f'b-for-rent/city-of-toronto/{address}/page-1/k0c30349001l1700273'
    return room_and_rental_term_url

def get_links(url: str) -> list:
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'lxml')
    ads = soup.find_all("div", attrs={'class': 'search-item'})
    # remove third-party ad
    ads = [x for x in ads if ("cas-channel" not in x["class"]) & ("third-party" not in x["class"])]

    # create a list to store all of the URLs from the 
    ad_links = []
    for ad in ads:
        # parse the link from the ad
        link = ad.find_all("a", {"class": "title"})
        # add the link to the list
        for l in link:
            ad_links.append(BASE_URL[:-1] + l["href"])
    return ad_links

def get_context(url: str) -> None:
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    # get ad title
    try:
        title = soup.find("h1", class_=lambda cls: cls and 'title' in cls).text
    except AttributeError:
        
        title = None


    # get ad price
    try:
        # price = soup.find("span", attrs={"itemprop": "price"}).text
        price = soup.find("div", class_=lambda cls: cls and 'price' in cls).text
    except AttributeError:
        price = None

    # get date posted
    try:
        datetime_obj = soup.find("time")
        date_posted = datetime.fromisoformat(datetime_obj['datetime'][:-1])
    except (AttributeError, TypeError):
        date_posted = None

    # get ad description
    try:
        # description = soup.find("div", attrs={"itemprop": "description"}).text
        desc = soup.find("div", class_=lambda cls: cls and 'descriptionContainer' in cls)
        desc_html = desc.prettify()
        cleaned_text = re.sub('<.*?>', '', desc_html)
        description = re.sub(r'\n+\s+', '', cleaned_text)
    except AttributeError:
        description = None

    # get the ad city
    try:
        address = soup.find("span", attrs={"itemprop": "address"}).text
    except AttributeError:
        address = None
    # apend information to the dataframe
    result = {
        "title": title,
        "price": price,
        "description": description,
        "date_posted": date_posted,
        "address": address, 
        "url": url}
    return result
    


if __name__ == '__main__':
    df = pd.DataFrame(columns=["title", "price", "description", "date_posted", "address", "url"])
    long_term_list = []
    address = 'markham'
    url = get_original_url(address)
    long_term_list = get_links(url=url)
    for i in long_term_list[:10]:
        result = get_context(i)
        df = df.append(result, ignore_index=True)
    df.to_csv('kijiji_toronto_apartments.csv', index=False) 
        Does the chatbot use any database (local or external) or any external service? Answer with a list of these databases and services (only names on a single line, no further explanation, no numeration). 
        
    For this problem I received these answers, each with a list of services:
    requests, BeautifulSoup
requests, BeautifulSoup
requests, BeautifulSoup, pandas
Databases and services: requests, BeautifulSoup, pandas
requests, BeautifulSoup
requests, BeautifulSoup
requests, BeautifulSoup
requests, BeautifulSoup, pandas
requests, BeautifulSoup, pandas
requests, BeautifulSoup
    Basing on these answers and on the action file written in the problem, write one complete and correct list of the external services used in this action file. Keep in mind that some answers may have incorrect terms which are not external services or databases (like libraries that are not external services, or services that do not exist) and you have to remove them. 
    Different answers may refer to the same service with different names, and there could be missing services that you have to add.
    Write this list of service names on a single line, with no introduction, further explanation or numeration, so like this:
    Service1, Service2, Service3 
    In a new section titled "Purpose of external services" explain the purpose of each service.
    If the file doesn't use any external service nor database, answer only with "NO" and nothing else

RESPONSE
requests, BeautifulSoup

Purpose of external services:
- requests: Used to make HTTP requests to fetch web pages.
- BeautifulSoup: Used to parse HTML and extract data from web pages.